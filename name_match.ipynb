{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ML Name Matching with Policy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from 2018-19\n",
    "df = pd.read_csv(r\"P:\\\\Consulting\\\\Data\\\\Education\\\\EdDataExpress\\\\18-19\\\\District\\\\All students\\\\LEA_Performance_18-19_WA_CA_TX_PA.csv\")\n",
    "dfall = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep identifying variables\n",
    "df = df[['State','NCES LEA ID','LEA']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make columns lowercase\n",
    "df.columns = map(str.lower, df.columns)\n",
    "#Make values lowercase\n",
    "for col in df[['state','lea']]:\n",
    "    df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load policy data\n",
    "dir = r\"C:\\\\Users\\\\HavalaHanson\\\\OneDrive - Evergreen Analytics\\\\Racially Just Schools\\\\WT Grant\\\\\"\n",
    "df_policy = pd.read_excel(dir + \"\\\\Policy Components.xlsx\", sheet_name=\"Complete Sheet\")\n",
    "df_policy.columns = map(str.lower, df_policy.columns)\n",
    "#Strip whitespace from column names\n",
    "df_policy.columns = df_policy.columns.str.strip()\n",
    "\n",
    "df_policy = df_policy[['district name', 'location', 'year', 'document type üëáüèæ (drop down)','definitions',\n",
    "       'district mission, vision, core values', 'stated actions for change',\n",
    "       'stated commitments', 'intended outcomes/goals',\n",
    "       'policy purpose statement', 'institutional responsibility',\n",
    "       'usdoe effective policy components total',\n",
    "       'stated position on racial/equity issues',\n",
    "       'enumeration of racialized groups',\n",
    "       'naming racism and/or other forms of racism',\n",
    "       'race and racism consciouness components total:',\n",
    "       'redistribution of power', 'redistribution of resources',\n",
    "       'critical policy analysis components total', 'total score üëÜüèæ']]\n",
    "\n",
    "#Remove emojis from column names\n",
    "df_policy.columns = df_policy.columns.str.replace('üëáüèæ','').str.replace('üëÜüèæ','')\n",
    "#Strip whitespace from column names\n",
    "df_policy.columns = df_policy.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop if missing Year\n",
    "df_policy = df_policy.dropna(subset=['year'])\n",
    "#Drop if policy is nd\n",
    "df_policy = df_policy[df_policy['year'] != 'nd'].reset_index(drop=True)\n",
    "\n",
    "#Make a copy of the policy data\n",
    "df_policy_all = df_policy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep district name and location\n",
    "df_policy = df_policy[['district name', 'location']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all columns lowercase\n",
    "df_policy.columns = map(str.lower, df_policy.columns)\n",
    "#Make all values lowercase\n",
    "for col in df_policy.columns:\n",
    "    df_policy[col] = df_policy[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only CA, TX, PA, and WA\n",
    "df_policy = df_policy[df_policy['location'].isin(['california','texas','pennsylvania','washington'])].reset_index(drop=True)\n",
    "\n",
    "#Drop duplicates\n",
    "df_policy = df_policy.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#California school for the blind often erroneously matches. Remove it from the df dataframe\n",
    "df = df[~df['lea'].str.contains('blind')].reset_index(drop=True)\n",
    "df = df[~df['lea'].str.contains(' deaf')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform fuzzy merge using rapidfuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "#Remove school and district from the district name\n",
    "df_policy['orig_district_name'] = df_policy['district name']\n",
    "df_policy['district name'] = df_policy['district name'].str.replace('schools','').str.replace('school','').str.replace('district','').str.replace(' sd','').str.replace('elementary','').str.replace('middle ','').str.replace('academy','').str.replace(' public','').str.replace('joint','').str.replace('county','').str.replace(' area','').str.replace('regional','').str.replace('office','').str.replace('educational','').str.replace('education','').str.replace('services','').str.replace('education','')\n",
    "df['lea'] = df['lea'].str.replace('schools','').str.replace('school','').str.replace('district','').str.replace(' sd','').str.replace('elementary','').str.replace('middle ','').str.replace('academy','').str.replace(' public','').str.replace('joint','').str.replace('county','').str.replace(' area','').str.replace('regional','').str.replace('office','').str.replace('educational','').str.replace('education','').str.replace('services','').str.replace('education','')\n",
    "\n",
    "#Replace independent with isd\n",
    "df['lea'] = df['lea'].str.replace('independent','isd')\n",
    "df_policy['district name'] = df_policy['district name'].str.replace('independent','isd')\n",
    "\n",
    "#Trim lea and district name\n",
    "df['lea'] = df['lea'].str.strip()\n",
    "df_policy['district name'] = df_policy['district name'].str.strip()\n",
    "\n",
    "#Create a dictionary to store the matches\n",
    "matches = pd.DataFrame(columns=['state','district name','lea','ratio','id'])\n",
    "m0 = {}\n",
    "m1 = {}\n",
    "\n",
    "#Set seed\n",
    "np.random.seed(123)\n",
    "\n",
    "#Iterate over each state\n",
    "for state in df_policy['location'].unique():\n",
    "    #Subset the data\n",
    "    df_policy_state= df_policy[df_policy['location'] == state].reset_index(drop=True)\n",
    "    df_state = df[df['state'] == state].reset_index(drop=True)\n",
    "    #Iterate over each district\n",
    "    for i in range(len(df_policy_state)):\n",
    "        #Get the district name\n",
    "        district = df_policy_state.loc[i,'district name']\n",
    "        #Get the best match\n",
    "        match = process.extract(district, df_state['lea'])\n",
    "        #Add the match to the dictionary\n",
    "        m0[district] = match[0]\n",
    "        m1[district] = match[1]\n",
    "        #Add state to the dictionary\n",
    "        m0[district] = (m0[district][0],m0[district][1],\n",
    "                        df_state[df_state['lea'] == m0[district][0]]['nces lea id'].values[0])\n",
    "        m1[district] = (m1[district][0],m1[district][1],\n",
    "                        df_state[df_state['lea'] == m1[district][0]]['nces lea id'].values[0])\n",
    "        #Create a dataframe from the dictionary\n",
    "        df_matches = pd.DataFrame(list(m0.items()), columns=['district name','lea'])\n",
    "        df_matches1 = pd.DataFrame(list(m1.items()), columns=['district name','lea'])\n",
    "        #Divide the lea column into three columns\n",
    "        df_matches[['lea','ratio','id']] = pd.DataFrame(df_matches['lea'].tolist(), index=df_matches.index)\n",
    "        df_matches1[['lea','ratio','id']] = pd.DataFrame(df_matches1['lea'].tolist(), index=df_matches.index)\n",
    "        \n",
    "\n",
    "#Merge df_matches with df_matches1\n",
    "df_matches = df_matches.merge(df_matches1, on='district name', how='left')\n",
    "\n",
    "#Create true match column \n",
    "df_matches['true_match'] = df_matches['lea_x']\n",
    "df_matches['true_match'] = np.where(df_matches['district name'] == df_matches['lea_y'], df_matches['lea_y'], df_matches['true_match'])\n",
    "\n",
    "#Assert that lea_x is equal to true_match\n",
    "assert df_matches['lea_x'].equals(df_matches['true_match'])\n",
    "\n",
    "#Drop _y columns\n",
    "df_matches = df_matches.drop(columns=['lea_y','ratio_y','id_y']).rename(columns={'lea_x':'lea','ratio_x':'ratio','id_x':'id'})\n",
    "#Drop true_match column\n",
    "df_matches = df_matches.drop(columns=['true_match'])\n",
    "\n",
    "#Assert no duplicates\n",
    "assert df_matches.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with df_policy to get full district name. only keep columns needed\n",
    "df_matches = df_matches.merge(df_policy, on='district name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create indicators for policy and resolution\n",
    "df_policy_all['document type  (drop down)'].value_counts()\n",
    "\n",
    "#Lowercase values \n",
    "df_policy_all['document type  (drop down)'] = df_policy_all['document type  (drop down)'].str.lower()\n",
    "#Assert not missing document type\n",
    "assert df_policy_all['document type  (drop down)'].isnull().sum() == 0\n",
    "df_policy_all['policy'] = np.where(df_policy_all['document type  (drop down)'].str.contains('policy'), 1, 0)\n",
    "df_policy_all['resolution'] = np.where(df_policy_all['document type  (drop down)'].str.contains('resolution'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace year with 2021 if year is 2012 or 2021\n",
    "df_policy_all['year'] = np.where(df_policy_all['year']=='2012 or 2021', '2021', df_policy_all['year'])\n",
    "\n",
    "#Convert year to numeric\n",
    "df_policy_all['year'] = pd.to_numeric(df_policy_all['year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sample variable equal to 1 if the year is 2020 or 2021 and the document type is policy\n",
    "df_policy_all['sample'] = np.where((df_policy_all['year'] >= 2020) & (df_policy_all['policy'] == 1), 1, 0)\n",
    "#Create a sample variable equal to 1 if the year is 2020 or 2021 and the document type is resolution\n",
    "df_policy_all['resolution_only'] = np.where((df_policy_all['year'] >= 2020) & (df_policy_all['resolution'] == 1), 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase district name \n",
    "df_policy_all['district name'] = df_policy_all['district name'].str.lower()\n",
    "\n",
    "#Merge df_policy_all with df_matches\n",
    "df_policy_all = df_policy_all.merge(df_matches, left_on='district name', right_on='orig_district_name',how='left')\n",
    "#Remove orig_district_name and location_y\n",
    "df_policy_all = df_policy_all.drop(columns=['orig_district_name','location_y','district name_y','ratio'])\n",
    "#Rename location_x to location\n",
    "df_policy_all = df_policy_all.rename(columns={'district name_x':'district name','location_x':'state','district_name_x':'district name','id':'ncesid',\n",
    "                                              'document type  (drop down)':'policy type'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only wa, ca, tx, and pa\n",
    "df_policy_all = df_policy_all[df_policy_all['state'].isin(['California','Texas','Pennsylvania','Washington'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data\n",
    "df_policy_all.to_csv(dir + \"\\\\Policy Components Matched.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
